{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW :\n",
    "- Load Data\n",
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.\n",
    "- Shuffle the data if needed.\n",
    "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
    "- Split into 60 and 40 ratio.\n",
    "- Encode labels.\n",
    "- Model : 1 hidden layers including 16 unit.\n",
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "- Train the Model with Epochs (100).\n",
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**\n",
    "- Evaluation Step\n",
    "- Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential # Sequential/Functional Api\n",
    "from tensorflow.keras.layers import Dense # type of layer\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.regularizers import l1\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.0</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1  feature2    feature3    feature4    feature5    feature6  \\\n",
       "count  351.000000     351.0  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738       0.0    0.641342    0.044372    0.601068    0.115889   \n",
       "std      0.311155       0.0    0.497708    0.441435    0.519862    0.460810   \n",
       "min      0.000000       0.0   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000       0.0    0.472135   -0.064735    0.412660   -0.024795   \n",
       "50%      1.000000       0.0    0.871110    0.016310    0.809200    0.022800   \n",
       "75%      1.000000       0.0    1.000000    0.194185    1.000000    0.334655   \n",
       "max      1.000000       0.0    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature7    feature8    feature9   feature10  ...   feature25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.550095    0.119360    0.511848    0.181345  ...    0.396135   \n",
       "std      0.492654    0.520750    0.507066    0.483851  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%      0.211310   -0.054840    0.087110   -0.048075  ...    0.000000   \n",
       "50%      0.728730    0.014710    0.684210    0.018290  ...    0.553890   \n",
       "75%      0.969240    0.445675    0.953240    0.534195  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ionosphere_data.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "count    351\n",
       "unique     2\n",
       "top        g\n",
       "freq     225"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    225\n",
       "b    126\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label_binary\"] = np.where(data[\"label\"]=='g', 1, 0)\n",
    "data = data.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47938</td>\n",
       "      <td>-0.12371</td>\n",
       "      <td>0.42784</td>\n",
       "      <td>-0.12371</td>\n",
       "      <td>0.70103</td>\n",
       "      <td>-0.39175</td>\n",
       "      <td>0.73196</td>\n",
       "      <td>0.07216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19588</td>\n",
       "      <td>0.53396</td>\n",
       "      <td>-0.12447</td>\n",
       "      <td>0.15464</td>\n",
       "      <td>-0.26289</td>\n",
       "      <td>0.47423</td>\n",
       "      <td>0.04124</td>\n",
       "      <td>0.45361</td>\n",
       "      <td>-0.51546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89706</td>\n",
       "      <td>0.38235</td>\n",
       "      <td>0.91176</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.74265</td>\n",
       "      <td>0.67647</td>\n",
       "      <td>0.45588</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12500</td>\n",
       "      <td>-0.67925</td>\n",
       "      <td>-0.24131</td>\n",
       "      <td>-0.55147</td>\n",
       "      <td>-0.42647</td>\n",
       "      <td>-0.44118</td>\n",
       "      <td>-0.50735</td>\n",
       "      <td>-0.28676</td>\n",
       "      <td>-0.56618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84134</td>\n",
       "      <td>-0.18362</td>\n",
       "      <td>0.43644</td>\n",
       "      <td>0.02919</td>\n",
       "      <td>0.93421</td>\n",
       "      <td>-0.00267</td>\n",
       "      <td>0.87947</td>\n",
       "      <td>0.13795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02778</td>\n",
       "      <td>0.93358</td>\n",
       "      <td>-0.01158</td>\n",
       "      <td>0.61582</td>\n",
       "      <td>-0.32298</td>\n",
       "      <td>0.84463</td>\n",
       "      <td>-0.25706</td>\n",
       "      <td>0.93323</td>\n",
       "      <td>-0.01425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>-0.99265</td>\n",
       "      <td>0.80882</td>\n",
       "      <td>0.55147</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "23          0         0  -1.00000   1.00000   0.00000   0.00000   0.00000   \n",
       "271         1         0   0.47938  -0.12371   0.42784  -0.12371   0.70103   \n",
       "135         1         0   0.89706   0.38235   0.91176   0.37500   0.74265   \n",
       "50          1         0   0.84134  -0.18362   0.43644   0.02919   0.93421   \n",
       "100         1         0   1.00000  -1.00000   0.00000   0.00000   0.77941   \n",
       "\n",
       "     feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "23    0.00000  -1.00000    1.00000  ...   -1.00000    1.00000   -1.00000   \n",
       "271  -0.39175   0.73196    0.07216  ...    0.19588    0.53396   -0.12447   \n",
       "135   0.67647   0.45588    0.77941  ...   -0.12500   -0.67925   -0.24131   \n",
       "50   -0.00267   0.87947    0.13795  ...   -0.02778    0.93358   -0.01158   \n",
       "100  -0.99265   0.80882    0.55147  ...   -1.00000   -1.00000   -1.00000   \n",
       "\n",
       "     feature29  feature30  feature31  feature32  feature33  feature34  \\\n",
       "23     1.00000    1.00000   -1.00000    1.00000    0.00000    0.00000   \n",
       "271    0.15464   -0.26289    0.47423    0.04124    0.45361   -0.51546   \n",
       "135   -0.55147   -0.42647   -0.44118   -0.50735   -0.28676   -0.56618   \n",
       "50     0.61582   -0.32298    0.84463   -0.25706    0.93323   -0.01425   \n",
       "100    1.00000   -1.00000    1.00000   -1.00000    0.00000    0.00000   \n",
       "\n",
       "     label_binary  \n",
       "23              0  \n",
       "271             1  \n",
       "135             1  \n",
       "50              1  \n",
       "100             0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1        0\n",
       "feature2        0\n",
       "feature3        0\n",
       "feature4        0\n",
       "feature5        0\n",
       "feature6        0\n",
       "feature7        0\n",
       "feature8        0\n",
       "feature9        0\n",
       "feature10       0\n",
       "feature11       0\n",
       "feature12       0\n",
       "feature13       0\n",
       "feature14       0\n",
       "feature15       0\n",
       "feature16       0\n",
       "feature17       0\n",
       "feature18       0\n",
       "feature19       0\n",
       "feature20       0\n",
       "feature21       0\n",
       "feature22       0\n",
       "feature23       0\n",
       "feature24       0\n",
       "feature25       0\n",
       "feature26       0\n",
       "feature27       0\n",
       "feature28       0\n",
       "feature29       0\n",
       "feature30       0\n",
       "feature31       0\n",
       "feature32       0\n",
       "feature33       0\n",
       "feature34       0\n",
       "label_binary    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.sample(frac=0.6, random_state=0) # will reserve 20% for validation during training\n",
    "test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target value, or “label”, from the features.\n",
    "train_labels = train_data.pop('label_binary')\n",
    "test_labels = test_data.pop('label_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "\n",
    "train_data.head()\n",
    "train_data.drop('feature2',axis=1, inplace=True)\n",
    "test_data.drop('feature2',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    from tensorflow import keras\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu',\n",
    "                           kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001),input_dim = 33))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(128, kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001), activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(64, kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001), activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(32, kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001), activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001), activation='relu'))    \n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 128)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 31,745\n",
      "Trainable params: 31,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53337324],\n",
       "       [0.50198084],\n",
       "       [0.47793365],\n",
       "       [0.5074225 ],\n",
       "       [0.52250266],\n",
       "       [0.51841193],\n",
       "       [0.5592905 ],\n",
       "       [0.52789414],\n",
       "       [0.52212805],\n",
       "       [0.51942414]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = train_data[:10]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168 samples, validate on 43 samples\n",
      "Epoch 1/100\n",
      " 32/168 [====>.........................] - ETA: 1s - loss: 3.7270 - acc: 0.5625\n",
      "Epoch: 0, acc:0.5833,  loss:3.6923,  val_acc:0.6279,  val_loss:3.6325,  \n",
      "168/168 [==============================] - 1s 5ms/sample - loss: 3.6923 - acc: 0.5833 - val_loss: 3.6325 - val_acc: 0.6279\n",
      "Epoch 2/100\n",
      "168/168 [==============================] - 0s 202us/sample - loss: 3.6022 - acc: 0.6190 - val_loss: 3.5241 - val_acc: 0.7442\n",
      "Epoch 3/100\n",
      "168/168 [==============================] - 0s 271us/sample - loss: 3.5065 - acc: 0.7083 - val_loss: 3.4114 - val_acc: 0.8140\n",
      "Epoch 4/100\n",
      "168/168 [==============================] - 0s 267us/sample - loss: 3.3804 - acc: 0.7202 - val_loss: 3.2917 - val_acc: 0.8372\n",
      "Epoch 5/100\n",
      "168/168 [==============================] - 0s 291us/sample - loss: 3.2635 - acc: 0.7917 - val_loss: 3.1715 - val_acc: 0.8372\n",
      "Epoch 6/100\n",
      "168/168 [==============================] - 0s 306us/sample - loss: 3.1070 - acc: 0.8571 - val_loss: 3.0530 - val_acc: 0.8372\n",
      "Epoch 7/100\n",
      "168/168 [==============================] - 0s 309us/sample - loss: 3.0148 - acc: 0.8512 - val_loss: 2.9411 - val_acc: 0.8837\n",
      "Epoch 8/100\n",
      "168/168 [==============================] - 0s 350us/sample - loss: 2.8956 - acc: 0.8929 - val_loss: 2.8230 - val_acc: 0.8837\n",
      "Epoch 9/100\n",
      "168/168 [==============================] - 0s 273us/sample - loss: 2.8086 - acc: 0.8869 - val_loss: 2.7252 - val_acc: 0.9070\n",
      "Epoch 10/100\n",
      "168/168 [==============================] - 0s 255us/sample - loss: 2.7091 - acc: 0.8810 - val_loss: 2.6328 - val_acc: 0.9302\n",
      "Epoch 11/100\n",
      "168/168 [==============================] - 0s 297us/sample - loss: 2.6030 - acc: 0.8988 - val_loss: 2.5542 - val_acc: 0.9302\n",
      "Epoch 12/100\n",
      "168/168 [==============================] - 0s 291us/sample - loss: 2.5296 - acc: 0.9226 - val_loss: 2.4840 - val_acc: 0.9302\n",
      "Epoch 13/100\n",
      "168/168 [==============================] - 0s 255us/sample - loss: 2.4682 - acc: 0.9286 - val_loss: 2.4422 - val_acc: 0.9302\n",
      "Epoch 14/100\n",
      "168/168 [==============================] - 0s 261us/sample - loss: 2.3993 - acc: 0.9226 - val_loss: 2.3704 - val_acc: 0.9302\n",
      "Epoch 15/100\n",
      "168/168 [==============================] - 0s 249us/sample - loss: 2.3285 - acc: 0.9405 - val_loss: 2.3033 - val_acc: 0.9302\n",
      "Epoch 16/100\n",
      "168/168 [==============================] - 0s 321us/sample - loss: 2.2234 - acc: 0.9524 - val_loss: 2.2534 - val_acc: 0.9302\n",
      "Epoch 17/100\n",
      "168/168 [==============================] - 0s 332us/sample - loss: 2.1820 - acc: 0.9643 - val_loss: 2.2115 - val_acc: 0.9302\n",
      "Epoch 18/100\n",
      "168/168 [==============================] - 0s 291us/sample - loss: 2.1525 - acc: 0.9583 - val_loss: 2.1451 - val_acc: 0.9302\n",
      "Epoch 19/100\n",
      "168/168 [==============================] - 0s 398us/sample - loss: 2.0560 - acc: 0.9524 - val_loss: 2.0893 - val_acc: 0.9302\n",
      "Epoch 20/100\n",
      "168/168 [==============================] - 0s 392us/sample - loss: 2.0091 - acc: 0.9583 - val_loss: 2.0333 - val_acc: 0.9302\n",
      "Epoch 21/100\n",
      "168/168 [==============================] - 0s 309us/sample - loss: 1.9533 - acc: 0.9464 - val_loss: 1.9870 - val_acc: 0.9302\n",
      "Epoch 22/100\n",
      "168/168 [==============================] - 0s 332us/sample - loss: 1.9008 - acc: 0.9702 - val_loss: 1.9512 - val_acc: 0.9302\n",
      "Epoch 23/100\n",
      "168/168 [==============================] - 0s 274us/sample - loss: 1.8631 - acc: 0.9643 - val_loss: 1.9132 - val_acc: 0.9302\n",
      "Epoch 24/100\n",
      "168/168 [==============================] - 0s 267us/sample - loss: 1.7994 - acc: 0.9762 - val_loss: 1.8572 - val_acc: 0.9302\n",
      "Epoch 25/100\n",
      "168/168 [==============================] - 0s 288us/sample - loss: 1.7403 - acc: 0.9643 - val_loss: 1.8127 - val_acc: 0.9302\n",
      "Epoch 26/100\n",
      "168/168 [==============================] - 0s 291us/sample - loss: 1.7013 - acc: 0.9702 - val_loss: 1.7741 - val_acc: 0.9302\n",
      "Epoch 27/100\n",
      "168/168 [==============================] - 0s 341us/sample - loss: 1.6308 - acc: 0.9821 - val_loss: 1.7270 - val_acc: 0.9302\n",
      "Epoch 28/100\n",
      "168/168 [==============================] - 0s 439us/sample - loss: 1.6079 - acc: 0.9762 - val_loss: 1.6817 - val_acc: 0.9302\n",
      "Epoch 29/100\n",
      "168/168 [==============================] - 0s 362us/sample - loss: 1.5356 - acc: 0.9821 - val_loss: 1.6632 - val_acc: 0.9302\n",
      "Epoch 30/100\n",
      "168/168 [==============================] - 0s 327us/sample - loss: 1.5041 - acc: 0.9702 - val_loss: 1.6416 - val_acc: 0.9302\n",
      "Epoch 31/100\n",
      "168/168 [==============================] - 0s 315us/sample - loss: 1.4545 - acc: 0.9762 - val_loss: 1.5799 - val_acc: 0.9302\n",
      "Epoch 32/100\n",
      "168/168 [==============================] - 0s 303us/sample - loss: 1.4128 - acc: 0.9881 - val_loss: 1.5188 - val_acc: 0.9302\n",
      "Epoch 33/100\n",
      "168/168 [==============================] - 0s 321us/sample - loss: 1.3933 - acc: 0.9702 - val_loss: 1.4890 - val_acc: 0.9302\n",
      "Epoch 34/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 1.3093 - acc: 1.0000 - 0s 330us/sample - loss: 1.3280 - acc: 0.9821 - val_loss: 1.4567 - val_acc: 0.9302\n",
      "Epoch 35/100\n",
      "168/168 [==============================] - 0s 285us/sample - loss: 1.2884 - acc: 0.9881 - val_loss: 1.4174 - val_acc: 0.9302\n",
      "Epoch 36/100\n",
      "168/168 [==============================] - 0s 321us/sample - loss: 1.2631 - acc: 0.9821 - val_loss: 1.3762 - val_acc: 0.9302\n",
      "Epoch 37/100\n",
      "168/168 [==============================] - 0s 321us/sample - loss: 1.2305 - acc: 0.9821 - val_loss: 1.3410 - val_acc: 0.9302\n",
      "Epoch 38/100\n",
      "168/168 [==============================] - 0s 285us/sample - loss: 1.1919 - acc: 0.9881 - val_loss: 1.3301 - val_acc: 0.9302\n",
      "Epoch 39/100\n",
      "168/168 [==============================] - 0s 321us/sample - loss: 1.1601 - acc: 0.9821 - val_loss: 1.3130 - val_acc: 0.9302\n",
      "Epoch 40/100\n",
      "168/168 [==============================] - 0s 392us/sample - loss: 1.1229 - acc: 0.9881 - val_loss: 1.2731 - val_acc: 0.9302\n",
      "Epoch 41/100\n",
      "168/168 [==============================] - 0s 439us/sample - loss: 1.1098 - acc: 0.9821 - val_loss: 1.2557 - val_acc: 0.9302\n",
      "Epoch 42/100\n",
      "168/168 [==============================] - 0s 321us/sample - loss: 1.0597 - acc: 0.9881 - val_loss: 1.2251 - val_acc: 0.9302\n",
      "Epoch 43/100\n",
      "168/168 [==============================] - 0s 327us/sample - loss: 1.0376 - acc: 0.9881 - val_loss: 1.1971 - val_acc: 0.9302\n",
      "Epoch 44/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 1.0958 - acc: 0.9688 - 0s 321us/sample - loss: 1.0299 - acc: 0.9821 - val_loss: 1.1776 - val_acc: 0.9302\n",
      "Epoch 45/100\n",
      "168/168 [==============================] - 0s 255us/sample - loss: 1.0100 - acc: 0.9702 - val_loss: 1.1661 - val_acc: 0.9302\n",
      "Epoch 46/100\n",
      "168/168 [==============================] - 0s 237us/sample - loss: 0.9770 - acc: 0.9881 - val_loss: 1.1216 - val_acc: 0.9302\n",
      "Epoch 47/100\n",
      "168/168 [==============================] - 0s 255us/sample - loss: 0.9502 - acc: 0.9821 - val_loss: 1.0589 - val_acc: 0.9302\n",
      "Epoch 48/100\n",
      "168/168 [==============================] - 0s 255us/sample - loss: 0.9309 - acc: 0.9702 - val_loss: 1.0040 - val_acc: 0.9302\n",
      "Epoch 49/100\n",
      "168/168 [==============================] - 0s 226us/sample - loss: 0.8989 - acc: 0.9881 - val_loss: 0.9832 - val_acc: 0.9302\n",
      "Epoch 50/100\n",
      "168/168 [==============================] - 0s 220us/sample - loss: 0.8749 - acc: 0.9940 - val_loss: 0.9810 - val_acc: 0.9302\n",
      "Epoch 51/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.8606 - acc: 0.9881 - val_loss: 0.9770 - val_acc: 0.9302\n",
      "Epoch 52/100\n",
      "168/168 [==============================] - 0s 226us/sample - loss: 0.8432 - acc: 0.9881 - val_loss: 0.9387 - val_acc: 0.9302\n",
      "Epoch 53/100\n",
      "168/168 [==============================] - 0s 261us/sample - loss: 0.8206 - acc: 0.9821 - val_loss: 0.9185 - val_acc: 0.9302\n",
      "Epoch 54/100\n",
      "168/168 [==============================] - 0s 255us/sample - loss: 0.8103 - acc: 0.9881 - val_loss: 0.9273 - val_acc: 0.9302\n",
      "Epoch 55/100\n",
      "168/168 [==============================] - 0s 226us/sample - loss: 0.7837 - acc: 0.9821 - val_loss: 0.9239 - val_acc: 0.9302\n",
      "Epoch 56/100\n",
      "168/168 [==============================] - 0s 208us/sample - loss: 0.7670 - acc: 0.9940 - val_loss: 0.8702 - val_acc: 0.9302\n",
      "Epoch 57/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.7612 - acc: 0.9821 - val_loss: 0.8546 - val_acc: 0.9302\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 237us/sample - loss: 0.7244 - acc: 0.9940 - val_loss: 0.8571 - val_acc: 0.9302\n",
      "Epoch 59/100\n",
      "168/168 [==============================] - 0s 214us/sample - loss: 0.7283 - acc: 0.9821 - val_loss: 0.8471 - val_acc: 0.9302\n",
      "Epoch 60/100\n",
      "168/168 [==============================] - 0s 261us/sample - loss: 0.7124 - acc: 0.9762 - val_loss: 0.8310 - val_acc: 0.9302\n",
      "Epoch 61/100\n",
      "168/168 [==============================] - 0s 193us/sample - loss: 0.6994 - acc: 0.9881 - val_loss: 0.8565 - val_acc: 0.9302\n",
      "Epoch 62/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.7063 - acc: 0.9643 - val_loss: 0.9466 - val_acc: 0.8605\n",
      "Epoch 63/100\n",
      "168/168 [==============================] - 0s 214us/sample - loss: 0.6904 - acc: 0.9762 - val_loss: 0.7898 - val_acc: 0.9302\n",
      "Epoch 64/100\n",
      "168/168 [==============================] - 0s 235us/sample - loss: 0.6588 - acc: 0.9821 - val_loss: 0.7871 - val_acc: 0.9302\n",
      "Epoch 65/100\n",
      "168/168 [==============================] - 0s 208us/sample - loss: 0.6357 - acc: 0.9940 - val_loss: 0.7785 - val_acc: 0.9302\n",
      "Epoch 66/100\n",
      "168/168 [==============================] - 0s 217us/sample - loss: 0.6332 - acc: 0.9881 - val_loss: 0.7671 - val_acc: 0.9302\n",
      "Epoch 67/100\n",
      "168/168 [==============================] - 0s 226us/sample - loss: 0.6283 - acc: 0.9940 - val_loss: 0.7552 - val_acc: 0.9302\n",
      "Epoch 68/100\n",
      "168/168 [==============================] - 0s 220us/sample - loss: 0.6162 - acc: 0.9881 - val_loss: 0.7592 - val_acc: 0.9302\n",
      "Epoch 69/100\n",
      "168/168 [==============================] - 0s 196us/sample - loss: 0.5984 - acc: 0.9940 - val_loss: 0.7558 - val_acc: 0.9302\n",
      "Epoch 70/100\n",
      "168/168 [==============================] - 0s 208us/sample - loss: 0.5898 - acc: 0.9821 - val_loss: 0.7431 - val_acc: 0.9302\n",
      "Epoch 71/100\n",
      "168/168 [==============================] - 0s 196us/sample - loss: 0.5710 - acc: 0.9881 - val_loss: 0.7184 - val_acc: 0.9302\n",
      "Epoch 72/100\n",
      "168/168 [==============================] - 0s 237us/sample - loss: 0.5620 - acc: 0.9940 - val_loss: 0.7049 - val_acc: 0.9302\n",
      "Epoch 73/100\n",
      "168/168 [==============================] - 0s 237us/sample - loss: 0.5464 - acc: 0.9881 - val_loss: 0.6864 - val_acc: 0.9302\n",
      "Epoch 74/100\n",
      "168/168 [==============================] - 0s 404us/sample - loss: 0.5437 - acc: 0.9881 - val_loss: 0.6821 - val_acc: 0.9302\n",
      "Epoch 75/100\n",
      "168/168 [==============================] - 0s 303us/sample - loss: 0.5484 - acc: 0.9881 - val_loss: 0.6783 - val_acc: 0.9302\n",
      "Epoch 76/100\n",
      "168/168 [==============================] - 0s 356us/sample - loss: 0.5275 - acc: 0.9881 - val_loss: 0.6816 - val_acc: 0.9302\n",
      "Epoch 77/100\n",
      "168/168 [==============================] - 0s 315us/sample - loss: 0.5168 - acc: 0.9881 - val_loss: 0.7086 - val_acc: 0.9070\n",
      "Epoch 78/100\n",
      "168/168 [==============================] - 0s 249us/sample - loss: 0.5090 - acc: 0.9821 - val_loss: 0.6484 - val_acc: 0.9302\n",
      "Epoch 79/100\n",
      "168/168 [==============================] - 0s 243us/sample - loss: 0.5009 - acc: 0.9881 - val_loss: 0.6221 - val_acc: 0.9302\n",
      "Epoch 80/100\n",
      "168/168 [==============================] - 0s 202us/sample - loss: 0.4958 - acc: 0.9881 - val_loss: 0.6225 - val_acc: 0.9302\n",
      "Epoch 81/100\n",
      "168/168 [==============================] - 0s 220us/sample - loss: 0.4869 - acc: 0.9940 - val_loss: 0.6186 - val_acc: 0.9302\n",
      "Epoch 82/100\n",
      "168/168 [==============================] - 0s 226us/sample - loss: 0.4704 - acc: 0.9940 - val_loss: 0.6378 - val_acc: 0.9302\n",
      "Epoch 83/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.4741 - acc: 0.9940 - val_loss: 0.6616 - val_acc: 0.9070\n",
      "Epoch 84/100\n",
      "168/168 [==============================] - 0s 243us/sample - loss: 0.4635 - acc: 0.9881 - val_loss: 0.6010 - val_acc: 0.9302\n",
      "Epoch 85/100\n",
      "168/168 [==============================] - 0s 249us/sample - loss: 0.4582 - acc: 0.9940 - val_loss: 0.5942 - val_acc: 0.9302\n",
      "Epoch 86/100\n",
      "168/168 [==============================] - 0s 220us/sample - loss: 0.4520 - acc: 0.9940 - val_loss: 0.5957 - val_acc: 0.9302\n",
      "Epoch 87/100\n",
      "168/168 [==============================] - 0s 214us/sample - loss: 0.4278 - acc: 0.9940 - val_loss: 0.5878 - val_acc: 0.9302\n",
      "Epoch 88/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.4538 - acc: 0.9821 - val_loss: 0.5971 - val_acc: 0.9302\n",
      "Epoch 89/100\n",
      "168/168 [==============================] - 0s 243us/sample - loss: 0.4276 - acc: 0.9881 - val_loss: 0.5765 - val_acc: 0.9302\n",
      "Epoch 90/100\n",
      "168/168 [==============================] - 0s 247us/sample - loss: 0.4183 - acc: 0.9940 - val_loss: 0.5608 - val_acc: 0.9302\n",
      "Epoch 91/100\n",
      "168/168 [==============================] - 0s 225us/sample - loss: 0.4170 - acc: 0.9881 - val_loss: 0.5558 - val_acc: 0.9302\n",
      "Epoch 92/100\n",
      "168/168 [==============================] - 0s 273us/sample - loss: 0.4118 - acc: 0.9940 - val_loss: 0.5971 - val_acc: 0.9070\n",
      "Epoch 93/100\n",
      "168/168 [==============================] - 0s 267us/sample - loss: 0.4084 - acc: 1.0000 - val_loss: 0.5717 - val_acc: 0.9302\n",
      "Epoch 94/100\n",
      "168/168 [==============================] - 0s 261us/sample - loss: 0.4150 - acc: 0.9881 - val_loss: 0.5759 - val_acc: 0.9302\n",
      "Epoch 95/100\n",
      "168/168 [==============================] - 0s 255us/sample - loss: 0.4114 - acc: 0.9821 - val_loss: 0.6104 - val_acc: 0.9070\n",
      "Epoch 96/100\n",
      "168/168 [==============================] - 0s 255us/sample - loss: 0.4018 - acc: 0.9821 - val_loss: 0.5199 - val_acc: 0.9302\n",
      "Epoch 97/100\n",
      "168/168 [==============================] - 0s 232us/sample - loss: 0.3908 - acc: 0.9881 - val_loss: 0.4951 - val_acc: 0.9302\n",
      "Epoch 98/100\n",
      "168/168 [==============================] - 0s 209us/sample - loss: 0.3954 - acc: 0.9881 - val_loss: 0.5236 - val_acc: 0.9302\n",
      "Epoch 99/100\n",
      "168/168 [==============================] - 0s 226us/sample - loss: 0.3666 - acc: 1.0000 - val_loss: 0.5469 - val_acc: 0.9070\n",
      "Epoch 100/100\n",
      "168/168 [==============================] - 0s 237us/sample - loss: 0.3817 - acc: 0.9881 - val_loss: 0.5446 - val_acc: 0.9070\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "history = model.fit(\n",
    "  train_data, train_labels,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=1,\n",
    "  callbacks=[tfdocs.modeling.EpochDots()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s 85us/sample - loss: 0.5246 - acc: 0.9357\n",
      "[ 0  1  4  7 10]\n",
      "[1 1 1 1 1]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "[loss, mae] = model.evaluate(test_data, test_labels, verbose=1)\n",
    "\n",
    "test_predictions = model.predict(test_data)\n",
    "\n",
    "frauds = np.where(test_labels[:]==1)[0]\n",
    "print(frauds[0:5])\n",
    "print(test_labels.values[frauds[0:5]])\n",
    "print(np.around(test_predictions[frauds[0:5]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
